# Word-to-CSV-NCC: NCC Document Processing System

A comprehensive system for processing National Construction Code (NCC) 2022 documents and Australian/New Zealand Standards (AS/NZS) into structured CSV format for database loading. Includes both command-line batch processing and a web-based clause highlighter interface.

## Features

- âœ… **NCC Volume Processing**: Convert NCC 2022 Volumes 1, 2, 3 from DOCX to structured CSV
- âœ… **AS/NZS Standards**: Process Australian and New Zealand standards documents
- âœ… **Legal-Grade Extraction**: 100% structural accuracy, 99%+ content accuracy
- âœ… **State Variations**: Capture jurisdictional variations for NSW, VIC, QLD, SA, WA, TAS, NT, ACT
- âœ… **Compliance Framework**: Extract OBJECTIVE â†’ FUNCTIONAL_STATEMENT â†’ PERFORMANCE_REQUIREMENT â†’ DTS_PROVISION hierarchies
- âœ… **Database Ready**: 72-column CSV schema optimized for PostgreSQL/MySQL
- âœ… **Web Interface**: Visual clause highlighter and Excel export tool
- âœ… **No LLM/AI**: All processing is deterministic and rule-based

---

## Table of Contents

- [Quick Start - NCC Processing](#quick-start---ncc-processing)
- [NCC CSV Generation](#ncc-csv-generation)
- [Web Interface - Clause Highlighter](#web-interface---clause-highlighter)
- [Technology Stack](#technology-stack)
- [Architecture Overview](#architecture-overview)
- [Complete Project Structure](#complete-project-structure)
- [Installation & Usage](#installation--usage)
- [Database Loading](#database-loading)
- [Development Guidelines](#development-guidelines)
- [Known Limitations](#known-limitations)
- [Troubleshooting](#troubleshooting)

---

## Quick Start - NCC Processing

### Generate NCC CSV Files

```bash
# Install dependencies
npm install

# Process NCC Volume 2 (Class 1 & 10 Housing)
NODE_OPTIONS='--max-old-space-size=8192 --expose-gc' npx tsx scripts/generate-ncc-csv-optimized.ts \
  --input Refined_ncc2022-volume-two.docx \
  --out output/ncc_v2.csv \
  --doc_id ncc2022 \
  --volume 'Volume Two' \
  --state_variation '' \
  --version_date 2022

# Process NCC Volume 3 (Plumbing Code)
NODE_OPTIONS='--max-old-space-size=8192 --expose-gc' npx tsx scripts/generate-ncc-csv-optimized.ts \
  --input Refined_ncc2022-volume-three.docx \
  --out output/ncc_v3.csv \
  --doc_id ncc2022 \
  --volume 'Volume Three' \
  --state_variation '' \
  --version_date 2022
```

### Expected Output

```
[1/5] Reading DOCX file: Refined_ncc2022-volume-two.docx
[1/5] File size: 3.30 MB
[2/5] Converting DOCX to HTML (this may take 30-60 seconds)...
[2/5] Conversion complete. HTML length: 1.39 MB
[3/5] Running garbage collection...
[3/5] Repairing HTML format...
[4/5] Building NCC units from HTML...
[4/5] Extracted 4782 NCC units
[5/5] Writing CSV to ncc_v2.csv...
âœ… SUCCESS: Wrote 4782 rows -> /home/runner/app/output/ncc_v2.csv
File size: 19505.24 KB
```

### Volume Processing Status

| Volume | File Size | Status | Rows Extracted | Output Size |
|--------|-----------|--------|----------------|-------------|
| Volume 2 | 3.4 MB | âœ… Success | 4,782 | 19.5 MB |
| Volume 3 | 3.8 MB | âœ… Success | 5,477 | 21.9 MB |
| Volume 1 | 7.2 MB | âš ï¸ Requires 16GB+ heap | TBD | TBD |

**Note**: Volume 1 requires local execution with increased memory:
```bash
NODE_OPTIONS='--max-old-space-size=16384 --expose-gc' npx tsx scripts/generate-ncc-csv-optimized.ts \
  --input ncc2022-volume-one.docx \
  --out output/ncc_v1.csv \
  --doc_id ncc2022 \
  --volume 'Volume One' \
  --state_variation '' \
  --version_date 2022
```

---

## NCC CSV Generation

### What Gets Extracted

The NCC processor extracts 51 different unit types including:

**Critical NCC Hierarchy:**
- `OBJECTIVE` - High-level safety/performance objectives
- `FUNCTIONAL_STATEMENT` - What the building must achieve
- `PERFORMANCE_REQUIREMENT` - Mandatory measurable requirements
- `DTS_PROVISION` - Deemed-to-Satisfy solutions (optional pathways)
- `VERIFICATION_METHOD` - Alternative compliance methods

**Supporting Elements:**
- `TABLE_ROW` / `TABLE` - Technical requirements and specifications
- `STATE_VARIATION` - Jurisdictional overrides (NSW, VIC, QLD, etc.)
- `GOVERNING_REQUIREMENT` - Section A administrative provisions
- `SPECIFICATION_CLAUSE` - Detailed technical specifications
- And 42+ other unit types

### CSV Schema (72 Columns)

Key columns include:
- `doc_id`, `volume`, `state_variation`, `version_date`
- `unit_label` (e.g., "H1P1", "B2D5"), `unit_type`, `compliance_weight`
- `title`, `text`, `text_html`
- `path`, `anchor_id`, `parent_anchor_id`
- `internal_refs`, `external_refs`, `satisfies_pr_ids`
- `applies_state`, `variation_action`, `affected_unit_label`
- `table_grid_json`, `formula_json`, `conditions_text`

### Terminal Output Guide

The processing script provides detailed progress logging:

```
[Stage X/5] Current operation
[NCC Extraction X%] Processing blocks: N/total (X%)
[NCC Extraction X%] Phase 2B: Processing row N/total (X%) - UNIT_TYPE...
```

**Processing Stages:**
1. Reading DOCX file
2. Converting DOCX to HTML (30-60 seconds)
3. Running garbage collection and repairing HTML
4. Building NCC units from HTML (longest stage)
5. Writing CSV output

**Quality Gates:**
- âœ… rag_text completeness check
- âœ… State variation instruction extraction
- âœ… Bad heading detection
- âœ… Core clause text validation
- âœ… Self-reference checks
- âœ… STATE_VARIATION base_unit_label validation
- âœ… Table extraction verification

---

## Web Interface - Clause Highlighter

- âœ… **DOCX Upload & Conversion**: Loads .docx files and converts them to HTML using Mammoth.js
- âœ… **Format Repair**: Automatically cleans formatting issues (gaps, broken lines, weird spacing) while preserving content
- âœ… **Clause Detection**: Detects Australian NCC / AS / AS-NZS clauses using deterministic regex patterns
- âœ… **Manual Mark/Unmark**: Click paragraphs to manually mark or unmark clauses
- âœ… **Excel Export**: Export all detected clauses to .xlsx format with clause numbers and text
- âœ… **Excel Processor**: Import and process existing Excel files with clause data
- âœ… **Clean View & Editor**: View cleaned document or edit in rich text editor
- âœ… **Table Extraction**: Automatically extracts tables from documents
- âœ… **No LLM/AI**: All processing is deterministic and rule-based

---

## Technology Stack

### Frontend
- **Next.js 14** - React framework with server-side rendering
- **React 18** - UI library
- **Material-UI (MUI) v5.14.0** - Component library with Emotion (CSS-in-JS)
- **TipTap** - Rich text editor for document editing

### Backend
- **Next.js API Routes** - Server-side API endpoints
- **Mammoth.js** - DOCX to HTML conversion
- **formidable** - File upload handling
- **sanitize-html** - HTML sanitization
- **unified/rehype** - HTML processing and format repair

### Data Processing
- **SheetJS (xlsx)** - Excel file generation and parsing
- **uuid** - Unique ID generation for clauses
- **Custom regex engine** - Clause detection patterns

---

## Architecture Overview

The application follows a **client-server architecture** with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React/Next.js)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ClausesWorkspace                                            â”‚
â”‚    â”œâ”€â”€ WordProcessor (Upload/View/Export)                   â”‚
â”‚    â”‚   â”œâ”€â”€ Document Upload                                  â”‚
â”‚    â”‚   â”œâ”€â”€ Clause Detection & Highlighting                â”‚
â”‚    â”‚   â”œâ”€â”€ Document Viewer (Clean/Editor)                  â”‚
â”‚    â”‚   â””â”€â”€ Excel Export                                     â”‚
â”‚    â””â”€â”€ ExcelProcessor (Import/Process)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†• HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend API (Next.js API Routes)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  /api/upload-docx                                           â”‚
â”‚    â”œâ”€â”€ File Upload (formidable)                             â”‚
â”‚    â”œâ”€â”€ DOCX â†’ HTML (Mammoth)                                â”‚
â”‚    â”œâ”€â”€ Format Repair Pipeline                               â”‚
â”‚    â””â”€â”€ Return Clean HTML/Text/Paragraphs                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Processing Libraries                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  lib/clause-detector.ts    - Regex-based clause detection   â”‚
â”‚  lib/format-repair.ts      - HTML/text cleanup              â”‚
â”‚  lib/table-extractor.ts    - Table extraction               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Project Structure

```
wordprocessor-clause-highlighter/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ _app.tsx                    # MUI ThemeProvider wrapper
â”‚   â”œâ”€â”€ index.tsx                   # Main entry point - renders ClausesWorkspace
â”‚   â”œâ”€â”€ excel-processor.tsx        # Standalone Excel processor page (optional route)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ upload-docx.ts         # API endpoint: DOCX upload, conversion, format repair
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ClausesWorkspace.tsx       # Main workspace with 3 sub-tabs
â”‚   â”œâ”€â”€ WordProcessor.tsx          # Core component: upload, view, clause management, export
â”‚   â”œâ”€â”€ ExcelProcessor.tsx         # Excel file import and processing
â”‚   â””â”€â”€ DocumentEditor.tsx        # TipTap rich text editor component
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ clause-detector.ts         # Regex-based clause detection engine
â”‚   â”œâ”€â”€ format-repair.ts           # HTML/text cleanup pipeline
â”‚   â””â”€â”€ table-extractor.ts         # Table extraction utilities
â”‚
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts                   # TypeScript interfaces (Clause, DocumentData, etc.)
â”‚
â”œâ”€â”€ styles/
â”‚   â””â”€â”€ globals.css                # Global CSS styles
â”‚
â”œâ”€â”€ package.json                   # Dependencies and scripts
â”œâ”€â”€ tsconfig.json                  # TypeScript config with @/* path alias
â”œâ”€â”€ next.config.js                 # Next.js config (10MB upload limit)
â””â”€â”€ README.md                      # This file
```

---

## How It Works

### 1. Document Upload Flow

```
User uploads .docx
    â†“
Frontend: FormData â†’ POST /api/upload-docx
    â†“
Backend: formidable parses multipart form
    â†“
Mammoth.js converts DOCX â†’ HTML (raw)
    â†“
Format Repair Pipeline:
  - Sanitize HTML (remove junk Word markup)
  - Normalize whitespace
  - Remove empty paragraphs
  - Join broken lines
  - Extract clean paragraphs
    â†“
Return: { html_clean, text_clean, paragraphs_clean }
    â†“
Frontend: Display document, auto-detect clauses
```

### 2. Clause Detection Flow

```
Clean paragraphs â†’ detectAllClauses()
    â†“
For each paragraph:
  - Try regex patterns in order (most specific first)
  - Extract clause number and text
  - Apply exclusion filters (tables, figures, etc.)
  - Create Clause object with unique ID
    â†“
Return: Clause[] array
    â†“
Frontend: Highlight clauses in document, show in sidebar
```

### 3. Manual Marking Flow

```
User clicks paragraph
    â†“
Check if clause already exists for this paragraph
    â†“
If exists: Remove clause (unmark)
If not: Prompt user for clause number
    â†“
Create new Clause object (markedBy: 'manual')
    â†“
Update state â†’ Re-render with highlight
```

### 4. Excel Export Flow

```
Clauses array â†’ Process
    â†“
Create SheetJS workbook
    â†“
Add worksheet with columns:
  - Column A: Clause Number
  - Column B: Clause Text
    â†“
Generate .xlsx file â†’ Download
```

---

## Component Details

### `pages/index.tsx`
**Purpose**: Main application entry point

**What it does**:
- Renders the `ClausesWorkspace` component
- Provides Material-UI container and theme

**Key Code**:
```typescript
export default function Home() {
  return (
    <Container maxWidth="xl" sx={{ py: 4 }}>
      <ClausesWorkspace />
    </Container>
  );
}
```

---

### `components/ClausesWorkspace.tsx`
**Purpose**: Main workspace container with tab navigation

**What it does**:
- Provides 3 sub-tabs: "Upload Word File", "Export to Excel", "Excel Processor"
- Routes to appropriate component based on selected tab
- Upload and Export tabs both use `WordProcessor` (same underlying workspace)

**State Management**:
- `subTab`: Current tab selection ('upload' | 'export' | 'excel')

**Key Code**:
```typescript
{(subTab === 'upload' || subTab === 'export') && (
  <WordProcessor />
)}

{subTab === 'excel' && (
  <ExcelProcessor />
)}
```

---

### `components/WordProcessor.tsx`
**Purpose**: Core document processing and clause management component

**What it does**:
1. **File Upload**: Handles .docx file selection and upload
2. **Document Display**: Shows document in "Clean" or "Editor" view mode
3. **Clause Detection**: Auto-detects clauses on document load
4. **Manual Marking**: Allows clicking paragraphs to mark/unmark clauses
5. **Clause Management**: Displays clauses in sidebar with delete functionality
6. **Excel Export**: Exports detected clauses to .xlsx file
7. **Table Extraction**: Extracts and displays tables from document

**State Management**:
- `documentData`: Processed document (HTML, text, paragraphs)
- `clauses`: Array of detected/manually marked clauses
- `tables`: Array of extracted tables
- `viewMode`: 'clean' | 'editor'
- `loading`: Upload/processing state
- `error`: Error messages
- `editedHtml`: Edited HTML from TipTap editor

**Key Functions**:
- `handleFileUpload()`: Uploads file, processes, detects clauses
- `toggleClauseHighlight()`: Marks/unmarks clauses on paragraph click
- `exportToExcel()`: Generates and downloads Excel file
- `handleEditorChange()`: Updates edited HTML from TipTap

**Clause Highlighting Logic**:
- Uses `data-clause-id` attributes on paragraph elements
- CSS classes: `.clause-highlight` for visual highlighting
- Sidebar shows all clauses with delete buttons
- Clicking highlighted paragraph unmarks it
- Clicking unmarked paragraph prompts for clause number

---

### `components/ExcelProcessor.tsx`
**Purpose**: Import and process existing Excel files with clause data

**What it does**:
1. **Excel Import**: Reads .xlsx files using SheetJS
2. **Comma Corruption Fix**: Automatically fixes OCR errors (commas â†’ dots in clause numbers)
3. **Data Validation**: Validates and cleans clause data
4. **CSV Export**: Exports processed data to CSV format
5. **Standard Prefix**: Allows setting standard prefix (e.g., "as3000") for clause numbers

**Key Functions**:
- `fixCommaCorruption()`: Fixes comma corruption in clause numbers (e.g., "4.4,2" â†’ "4.4.2")
- `handleExcelUpload()`: Processes uploaded Excel file
- `exportToCSV()`: Exports processed data to CSV

**Comma Corruption Rules**:
- **Rule A**: Simple continuation - `4.4,2` â†’ `4.4.2`
- **Rule B**: Deeper continuation - `8.3,1.3.3` â†’ `8.3.1.3.3`
- **Rule C**: Ambiguous cases - requires user confirmation

---

### `components/DocumentEditor.tsx`
**Purpose**: Rich text editor using TipTap

**What it does**:
- Displays document HTML in editable TipTap editor
- Allows editing document content
- Preserves formatting (bold, italic, headings, lists)
- Emits changes back to parent component

**TipTap Extensions**:
- StarterKit (basic formatting)
- Document (multi-column support)
- Placeholder (shows placeholder text)

---

### `pages/api/upload-docx.ts`
**Purpose**: Server-side API endpoint for DOCX processing

**What it does**:
1. Receives .docx file via multipart/form-data
2. Validates file type (.docx only, rejects .doc)
3. Converts DOCX to HTML using Mammoth.js
4. Applies format repair pipeline
5. Returns cleaned HTML, text, and paragraphs

**Process Flow**:
```
POST /api/upload-docx
  â†“
formidable.parse() â†’ Extract file
  â†“
mammoth.convertToHtml() â†’ HTML (raw)
  â†“
repairFormat() â†’ { html_clean, text_clean, paragraphs_clean }
  â†“
Return JSON response
```

**Error Handling**:
- Validates .docx file type
- Rejects .doc files with helpful error message
- Handles file size limits (10MB)
- Returns structured error responses

---

### `lib/clause-detector.ts`
**Purpose**: Regex-based clause detection engine

**What it does**:
- Defines regex patterns for different clause formats
- Tries patterns in order (most specific first)
- Filters false positives (tables, figures, etc.)
- Returns array of detected clauses

**Clause Patterns** (in order of specificity):

1. **Clauses with subclause**: `D1.6(a)`, `2.6.3.3.2(a)`, `E2.2a(b)`
   ```regex
   /^\s*((?:\d+(?:\.\d+){1,4})|(?:[A-Z]{1,2}\d+(?:\.\d+)*[a-z]?)|(?:[A-Z]\.\d+(?:\.\d+){0,3}))(\([a-zivx]+\))?\s*[ .\-â€“:]*\s*(.*)$/
   ```

2. **Numeric clauses**: `2.6`, `2.6.3`, `2.6.3.3.2`
   ```regex
   /^\s*(\d+(?:\.\d+){1,4})\s*[ .\-â€“:]*\s*(.*)$/
   ```

3. **Lettered clauses**: `E2.2`, `E2.2a`, `FP1.4`, `CP1`, `GP5.2`
   ```regex
   /^\s*([A-Z]{1,2}\d+(?:\.\d+)*[a-z]?)\s*[ .\-â€“:]*\s*(.*)$/
   ```

4. **Appendix clauses**: `A.1`, `A.1.2`, `B.3.4.1`
   ```regex
   /^\s*([A-Z]\.\d+(?:\.\d+){0,3})\s*[ .\-â€“:]*\s*(.*)$/
   ```

**Exclusion Filters**:
- Table references: "Table", "TABLE", "Tab."
- Figure references: "Figure", "FIGURE", "Fig."
- Page references: "Page", "P.", "pp."
- Unit measurements: "mm", "mÂ²", "kg/mÂ³"
- Empty or very short text
- Text starting with numbers only (likely not clauses)

**Key Function**:
```typescript
export function detectAllClauses(paragraphs: string[]): Clause[]
```

---

### `lib/format-repair.ts`
**Purpose**: HTML and text cleanup pipeline

**What it does**:
1. **HTML Sanitization**: Removes junk Word markup while preserving structure
2. **Whitespace Normalization**: Removes multiple spaces, normalizes newlines
3. **Empty Paragraph Removal**: Cleans up empty or duplicate paragraphs
4. **Line Break Joining**: Joins broken lines caused by Word line-wrap
5. **De-hyphenation**: Fixes wrapped words (e.g., "inter-\nnational" â†’ "international")

**Important**: The repair pipeline does NOT rewrite or paraphrase content. It only fixes formatting issues deterministically.

**Key Functions**:
- `repairFormat()`: Main entry point - returns cleaned HTML, text, and paragraphs
- `sanitizeHtmlContent()`: Removes unsafe HTML while preserving structure
- `normalizeWhitespace()`: Normalizes whitespace (less aggressive to preserve clause numbers)
- `removeEmptyParagraphs()`: Removes empty `<p>` tags
- `joinBrokenLines()`: Joins hyphenated line breaks
- `extractParagraphs()`: Extracts paragraphs from HTML

**Sanitization Rules**:
- **Allowed tags**: `p`, `h1-h6`, `ul`, `ol`, `li`, `table`, `thead`, `tbody`, `tr`, `th`, `td`, `strong`, `em`, `b`, `i`, `u`, `br`, `span`, `div`, `blockquote`
- **Allowed attributes**: `class`, `id`, `style` (with restrictions)
- **Allowed styles**: `text-align`, `font-weight`, `font-style`

---

### `lib/table-extractor.ts`
**Purpose**: Extract tables from HTML documents

**What it does**:
- Finds all `<table>` elements in HTML
- Extracts table structure (headers, rows, cells)
- Generates metadata (row count, column count)
- Returns array of `ExtractedTable` objects

**Key Function**:
```typescript
export function extractTables(html: string, paragraphs: string[]): ExtractedTable[]
```

---

### `types/index.ts`
**Purpose**: TypeScript type definitions

**Key Interfaces**:

```typescript
interface Clause {
  id: string;                    // Unique UUID
  clauseNumber: string;           // e.g., "2.6.3", "E2.2a"
  text: string;                  // Clause text content
  paragraphIndex: number;         // Index in paragraphs array
  markedBy: 'auto' | 'manual';    // How it was detected
}

interface DocumentData {
  html_clean: string;            // Cleaned HTML
  text_clean: string;            // Cleaned text
  paragraphs_clean: string[];    // Array of paragraph strings
}

interface ExtractedTable {
  id: string;
  html: string;
  rowCount: number;
  columnCount: number;
}
```

---

## Data Flow

### Complete Processing Pipeline

```
1. User uploads .docx file
   â†“
2. Frontend: FormData â†’ POST /api/upload-docx
   â†“
3. Backend: formidable.parse() â†’ Extract file
   â†“
4. Backend: mammoth.convertToHtml() â†’ HTML (raw)
   â†“
5. Backend: repairFormat()
   â”œâ”€â”€ sanitizeHtmlContent() â†’ Remove junk markup
   â”œâ”€â”€ removeEmptyParagraphs() â†’ Clean empty tags
   â”œâ”€â”€ cleanHtmlStructure() â†’ Rehype processing
   â”œâ”€â”€ normalizeWhitespace() â†’ Normalize spacing
   â”œâ”€â”€ joinBrokenLines() â†’ Fix line breaks
   â””â”€â”€ extractParagraphs() â†’ Extract paragraph array
   â†“
6. Backend: Return { html_clean, text_clean, paragraphs_clean }
   â†“
7. Frontend: Receive DocumentData
   â†“
8. Frontend: detectAllClauses(paragraphs_clean)
   â”œâ”€â”€ For each paragraph:
   â”‚   â”œâ”€â”€ Try regex patterns (most specific first)
   â”‚   â”œâ”€â”€ Extract clause number and text
   â”‚   â”œâ”€â”€ Apply exclusion filters
   â”‚   â””â”€â”€ Create Clause object
   â””â”€â”€ Return Clause[]
   â†“
9. Frontend: extractTables(html_clean, paragraphs_clean)
   â””â”€â”€ Return ExtractedTable[]
   â†“
10. Frontend: Display document with highlights
    â”œâ”€â”€ Render HTML with clause highlights
    â”œâ”€â”€ Show clauses in sidebar
    â””â”€â”€ Show tables in sidebar
```

### State Management Flow

```
WordProcessor Component State:
â”œâ”€â”€ documentData: DocumentData | null
â”‚   â””â”€â”€ Set on file upload
â”‚
â”œâ”€â”€ clauses: Clause[]
â”‚   â”œâ”€â”€ Initial: Auto-detected from paragraphs
â”‚   â”œâ”€â”€ Updated: On manual mark/unmark
â”‚   â””â”€â”€ Used: For highlighting and export
â”‚
â”œâ”€â”€ tables: ExtractedTable[]
â”‚   â””â”€â”€ Set on file upload
â”‚
â”œâ”€â”€ viewMode: 'clean' | 'editor'
â”‚   â””â”€â”€ Toggled by user
â”‚
â””â”€â”€ editedHtml: string | null
    â””â”€â”€ Updated from TipTap editor
```

---

## Installation & Usage

### Installation

1. **Clone this repository**:
   ```bash
   git clone https://github.com/nsaqib238/Word-to-CSV-NCC.git
   cd Word-to-CSV-NCC
   ```

2. **Install dependencies**:
   ```bash
   npm install
   ```
   
   This installs all required packages including:
   - Next.js 14, React 18
   - Material-UI v5.14.0
   - Mammoth.js (DOCX conversion)
   - SheetJS/xlsx (Excel export)
   - TipTap (rich text editor)
   - TypeScript and tsx for CLI scripts

### Command-Line Usage (NCC Processing)

**Process NCC Documents:**
```bash
NODE_OPTIONS='--max-old-space-size=8192 --expose-gc' npx tsx scripts/generate-ncc-csv-optimized.ts \
  --input <input-file.docx> \
  --out <output-file.csv> \
  --doc_id ncc2022 \
  --volume '<Volume Name>' \
  --state_variation '' \
  --version_date 2022
```

**Parameters:**
- `--input`: Path to NCC DOCX file
- `--out`: Output CSV file path
- `--doc_id`: Document identifier (e.g., "ncc2022")
- `--volume`: Volume name (e.g., "Volume Two")
- `--state_variation`: State code if processing variation (empty string for base document)
- `--version_date`: NCC version year

**Memory Requirements:**
- Volume 2 (3.4 MB): 8GB heap âœ…
- Volume 3 (3.8 MB): 8GB heap âœ…
- Volume 1 (7.2 MB): 16GB+ heap required

### Web Interface Usage

1. **Run the development server**:
   ```bash
   npm run dev
   ```

2. **Open your browser**:
   Navigate to [http://localhost:3000](http://localhost:3000)

3. **Access the application**:
   - Local: `http://localhost:3000`
   - Network: Check terminal for network address (e.g., `http://192.168.x.x:3000`)

### Usage

#### Uploading a Document

1. Click the **"Upload Word File"** button
2. Select a .docx file from your computer
3. The document will be processed and displayed in the viewer

**Note**: Only .docx files are supported. If you have a .doc file (older format), please convert it to .docx first by opening it in Microsoft Word and saving as .docx format.

#### Viewing Documents

- Use the **"View: Clean"** button to view the document after format repair
- Use the **"View: Editor"** button to edit the document in a rich text editor
- The clean view shows the document with formatting issues automatically fixed

#### Clause Detection

Clauses are automatically detected when you upload a document. The system recognizes:

- **Numeric clauses**: `2.6`, `2.6.3`, `2.6.3.3.2`
- **Lettered clauses**: `E2.2`, `E2.2a`, `FP1.4`, `CP1`, `GP5.2`
- **Appendix clauses**: `A.1`, `A.1.2`, `B.3.4.1`
- **Clauses with subclauses**: `D1.6(a)`, `2.6.3.3.2(a)`

#### Manual Marking/Unmarking

- **To mark a clause**: Click on any unmarked paragraph. You'll be prompted to enter a clause number.
- **To unmark a clause**: Click on a highlighted clause, or click the delete icon (ğŸ—‘ï¸) in the clause sidebar.

#### Exporting to Excel

1. Ensure you have detected clauses (they appear in the sidebar)
2. Click the **"Export to Excel"** button
3. A file named `clauses.xlsx` will be downloaded with:
   - **Column A**: Clause Number
   - **Column B**: Clause Text

#### Excel Processor

1. Go to the **"Excel Processor"** tab
2. Upload an existing Excel file with clause data
3. The system will:
   - Fix comma corruption in clause numbers (e.g., "4.4,2" â†’ "4.4.2")
   - Validate and clean data
   - Allow export to CSV format

---

## Database Loading

### PostgreSQL Import

```sql
-- Create table (simplified schema)
CREATE TABLE ncc_units (
  doc_id VARCHAR(50),
  volume VARCHAR(50),
  state_variation VARCHAR(10),
  version_date INTEGER,
  source_file VARCHAR(255),
  path TEXT,
  anchor_id VARCHAR(255),
  parent_anchor_id VARCHAR(255),
  unit_label VARCHAR(100),
  unit_type VARCHAR(100),
  compliance_weight VARCHAR(50),
  title TEXT,
  text TEXT,
  text_html TEXT,
  -- ... (72 columns total, see CSV header)
);

-- Import Volume 2
\COPY ncc_units FROM 'output/ncc_v2.csv' WITH (FORMAT csv, HEADER true, DELIMITER ',', QUOTE '"', ESCAPE '"');

-- Import Volume 3
\COPY ncc_units FROM 'output/ncc_v3.csv' WITH (FORMAT csv, HEADER true, DELIMITER ',', QUOTE '"', ESCAPE '"');

-- Verify import
SELECT volume, unit_type, COUNT(*) 
FROM ncc_units 
GROUP BY volume, unit_type 
ORDER BY volume, COUNT(*) DESC;
```

### Query Examples

```sql
-- Get all Performance Requirements for Volume 2
SELECT unit_label, title, text 
FROM ncc_units 
WHERE volume = 'Volume Two' 
  AND unit_type = 'PERFORMANCE_REQUIREMENT'
ORDER BY unit_label;

-- Get NSW-specific variations
SELECT unit_label, variation_action, affected_unit_label, text
FROM ncc_units
WHERE applies_state = 'NSW';

-- Get all Structure provisions (Part H1)
SELECT unit_label, unit_type, compliance_weight, title
FROM ncc_units
WHERE volume = 'Volume Two'
  AND unit_label LIKE 'H1%'
ORDER BY unit_label;

-- Find clauses referencing AS/NZS 1170 (structural loads)
SELECT unit_label, unit_type, title
FROM ncc_units
WHERE external_refs LIKE '%AS/NZS 1170%';
```

### Validation Queries

```sql
-- Check extraction completeness for Volume 2
SELECT 
  'OBJECTIVE' as clause_type, 
  COUNT(*) as count,
  STRING_AGG(unit_label, ', ' ORDER BY unit_label) as labels
FROM ncc_units 
WHERE volume = 'Volume Two' AND unit_type = 'OBJECTIVE'
UNION ALL
SELECT 'FUNCTIONAL_STATEMENT', COUNT(*), STRING_AGG(unit_label, ', ' ORDER BY unit_label)
FROM ncc_units WHERE volume = 'Volume Two' AND unit_type = 'FUNCTIONAL_STATEMENT'
UNION ALL
SELECT 'PERFORMANCE_REQUIREMENT', COUNT(*), STRING_AGG(unit_label, ', ' ORDER BY unit_label)
FROM ncc_units WHERE volume = 'Volume Two' AND unit_type = 'PERFORMANCE_REQUIREMENT'
UNION ALL
SELECT 'DTS_PROVISION', COUNT(*), STRING_AGG(unit_label, ', ' ORDER BY unit_label)
FROM ncc_units WHERE volume = 'Volume Two' AND unit_type = 'DTS_PROVISION';

-- Expected results for Volume 2:
-- OBJECTIVE: 14 (H1O1, H2O1, H3O1, H4O1-H4O7, H5O1, H6O1, H7O1, H8O1)
-- FUNCTIONAL_STATEMENT: 21
-- PERFORMANCE_REQUIREMENT: 26
-- DTS_PROVISION: 43
```

---

## Extending the System

### Adding New Clause Detection Patterns

To add new clause detection patterns or modify existing ones:

1. **Edit `lib/clause-detector.ts`**:
   - Add new regex patterns to the `CLAUSE_PATTERNS` array
   - Patterns are tried in order (most specific first)
   - Each pattern should extract `clauseNumber` and `text`

2. **Add exclusion filters**:
   - Edit the `shouldExclude()` function to filter out false positives
   - Current exclusions: tables, figures, page references, unit measurements

3. **Example pattern addition**:
   ```typescript
   {
     name: 'custom_pattern',
     regex: /^\s*(YOUR_PATTERN)\b[ .\-â€“:]?(.*)$/,
     extractGroups: (match: RegExpMatchArray) => ({
       clauseNumber: match[1],
       text: (match[2] || '').trim()
     })
   }
   ```

### Adding New Export Formats

To add new export formats (e.g., CSV, JSON):

1. Create a new function in the appropriate component
2. Use SheetJS or a similar library to generate the file
3. Add a new button/action in the UI
4. Follow the existing Excel export pattern

### Adding New File Format Support

To support additional file formats (e.g., PDF, RTF):

1. Add a new API endpoint in `pages/api/`
2. Use appropriate conversion library (e.g., pdf-parse for PDF)
3. Integrate with existing format repair pipeline
4. Update file validation in upload handler

---

## Development Guidelines

### Code Preservation Principle

**IMPORTANT**: When making future changes to this codebase, the existing code must be preserved and not heavily modified.

#### Guidelines for Future Changes:

1. **Preserve Existing Functionality**
   - Do not remove or drastically alter existing features
   - Maintain backward compatibility
   - Keep existing code structure intact

2. **Additive Changes Preferred**
   - Prefer adding new features over modifying existing ones
   - Use feature flags or configuration when possible
   - Extend functionality rather than replace it

3. **Minimal Impact Modifications**
   - When fixes are needed, make surgical changes
   - Preserve existing function signatures and interfaces
   - Maintain existing data structures and types

4. **Documentation of Changes**
   - Document any necessary breaking changes
   - Provide migration paths if interfaces must change
   - Update this README when making significant architectural decisions

5. **Testing Before Changes**
   - Verify existing functionality still works after changes
   - Test with existing documents and use cases
   - Ensure clause detection patterns remain functional

### Key Components to Preserve:

- **Clause Detection Engine** (`lib/clause-detector.ts`) - Regex patterns are working well
- **Format Repair Pipeline** (`lib/format-repair.ts`) - Carefully tuned to preserve clause numbers
- **Document Upload/Processing** (`pages/api/upload-docx.ts`) - Stable conversion pipeline
- **UI Components** (`components/WordProcessor.tsx`) - Functional document viewer and clause management

### Areas That Can Be Extended:

- Additional clause detection patterns (add new patterns, don't modify existing ones)
- New export formats (add alongside Excel export)
- Additional file format support (add new handlers, keep .docx support)
- UI enhancements (add features, preserve existing layout)

---

## Known Limitations

- **Large documents (>10MB)**: May take longer to process
- **Complex table formatting**: May not be perfectly preserved
- **Word-specific formatting**: Some Word-specific formatting (e.g., tracked changes) is not supported
- **Pure subclauses**: Like `(a)`, `(i)` are detected but not exported by default
- **.doc files**: Older .doc format is not supported (must convert to .docx)
- **File size limit**: 10MB upload limit (configurable in `next.config.js`)

---

## Troubleshooting

### File upload fails

- Ensure the file is a valid .docx file
- Check file size (limit is 10MB, configurable)
- Check browser console for errors
- Verify the file is not corrupted

### Clauses not detected

- Verify the document contains clause numbers matching the regex patterns
- Try manually marking clauses if auto-detection misses them
- Check the exclusion filters in `lib/clause-detector.ts`
- Ensure format repair didn't corrupt clause numbers

### Formatting looks wrong

- Try switching between "Clean" and "Editor" views
- Some Word formatting may not convert perfectly
- Check the format repair pipeline settings in `lib/format-repair.ts`
- Verify the original .docx file is not corrupted

### Excel export fails

- Ensure you have at least one clause detected
- Check browser console for errors
- Verify SheetJS library is properly installed
- Try exporting with a smaller number of clauses first

### Excel processor issues

- Verify the Excel file has the expected column structure
- Check for comma corruption in clause numbers
- Ensure the file is not password-protected
- Verify the file is a valid .xlsx format

---

## License

This project is provided as-is for local use.

---

## Notes for Future Extension

- **Notes/Exceptions**: To add support for notes and exceptions, extend the clause detection to recognize patterns like "Note:", "Exception:", and link them to parent clauses
- **Figures/Tables**: Currently extracted but could be enhanced with better metadata extraction
- **Cross-references**: Could be added to detect and link clause references within the document
- **Multiple documents**: Could be extended to process multiple documents and merge clause lists
- **Batch processing**: Could add support for processing multiple files at once
- **Cloud storage**: Could integrate with cloud storage services for document management

---

**Last Updated**: Current session  
**Status**: Code is stable and functional - preserve this state
